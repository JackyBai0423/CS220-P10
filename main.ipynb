{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project: p10\n",
    "# submitter: bai59\n",
    "# partner: none\n",
    "# hours: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from collections import namedtuple\n",
    "# you may use from style of import to import JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in(pathname):\n",
    "    res = []\n",
    "    for i in os.listdir(pathname):\n",
    "        if(i[0]!='.'):\n",
    "            res.append(i)\n",
    "    sorted(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channel_ids1.json',\n",
       " 'channel_ids2.json',\n",
       " 'channel_ids3.json',\n",
       " 'channel_ids4.json',\n",
       " 'channel_ids5.json',\n",
       " 'comment_data1.csv',\n",
       " 'comment_data2.csv',\n",
       " 'comment_data3.csv',\n",
       " 'comment_data4.csv',\n",
       " 'comment_data5.csv',\n",
       " 'video_data.csv',\n",
       " 'video_ids.json']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q1\n",
    "list_files_in(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_paths_in(pathname):\n",
    "    return [os.path.join(pathname,i) for i in list_files_in(pathname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\channel_ids1.json',\n",
       " 'data\\\\channel_ids2.json',\n",
       " 'data\\\\channel_ids3.json',\n",
       " 'data\\\\channel_ids4.json',\n",
       " 'data\\\\channel_ids5.json',\n",
       " 'data\\\\comment_data1.csv',\n",
       " 'data\\\\comment_data2.csv',\n",
       " 'data\\\\comment_data3.csv',\n",
       " 'data\\\\comment_data4.csv',\n",
       " 'data\\\\comment_data5.csv',\n",
       " 'data\\\\video_data.csv',\n",
       " 'data\\\\video_ids.json']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q2\n",
    "list_paths_in_data = list_paths_in(\"data\")\n",
    "list_paths_in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\comment_data1.csv',\n",
       " 'data\\\\comment_data2.csv',\n",
       " 'data\\\\comment_data3.csv',\n",
       " 'data\\\\comment_data4.csv',\n",
       " 'data\\\\comment_data5.csv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q3\n",
    "comment_paths = [i for i in list_paths_in_data if 'comment_data' in i]\n",
    "comment_paths.sort()\n",
    "comment_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\channel_ids1.json',\n",
       " 'data\\\\channel_ids2.json',\n",
       " 'data\\\\channel_ids3.json',\n",
       " 'data\\\\channel_ids4.json',\n",
       " 'data\\\\channel_ids5.json']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q4\n",
    "channel_paths = [i for i in list_paths_in_data if 'channel_ids' in i]\n",
    "channel_paths.sort()\n",
    "channel_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f) # dict, list, etc\n",
    "def get_mapping(pathname):\n",
    "    try:\n",
    "        return read_json(pathname)\n",
    "    except json.JSONDecodeError:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Al Jazeera English'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q5\n",
    "get_mapping(os.path.join(\"data\", \"channel_ids1.json\"))['UCNye-wNBqNL5ZzHSJj3l8Bg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q6\n",
    "channel_dict = {}\n",
    "counter = 0\n",
    "for i in channel_paths:\n",
    "    for j in get_mapping(i).items():\n",
    "        channel_dict[j[0]] = j[1]\n",
    "        counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Comment = namedtuple(\"Comment\",[\"video_id\",\"comment_length\",\"author_id\",\"likes\",\"published_at\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need process_csv in order to complete get_comment_data.\n",
    "# If you already copy/pasted it from lab, please ignore this copy.\n",
    "def process_csv(filename):\n",
    "    exampleFile = open(filename, encoding=\"utf-8\")  \n",
    "    exampleReader = csv.reader(exampleFile)\n",
    "    exampleData = list(exampleReader)        \n",
    "    exampleFile.close()  \n",
    "    return exampleData\n",
    "\n",
    "def get_comment_data(comment_file):\n",
    "    csv_data = process_csv(comment_file)\n",
    "    header = csv_data[0]\n",
    "    comment_rows = csv_data[1:]\n",
    "    comment_id_idx = header.index(\"comment_id\")\n",
    "    video_id_idx = header.index(\"video_id\")\n",
    "    comment_length_idx = header.index(\"comment_length\")\n",
    "    author_id_idx = header.index(\"author_id\")\n",
    "    likes_idx = header.index(\"likes\")\n",
    "    published_at_idx = header.index(\"published_at\")\n",
    "    # Iterate over comment_rows\n",
    "    res = {}\n",
    "    for i in comment_rows:\n",
    "        if len(i) != 6 or '' in i:\n",
    "            continue\n",
    "        try:\n",
    "            res[i[comment_id_idx]] = Comment(i[video_id_idx],int(i[comment_length_idx]),i[author_id_idx],int(i[likes_idx]),i[published_at_idx])\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comment(video_id='udNXMAflbU8', comment_length=175, author_id='UCHkk7x38KWgqjQOHqsQwf0Q', likes=47, published_at='2021-10-10 17:48:38')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q7\n",
    "#What is the Comment object with comment ID UgygOezB4Mvd5o6FgAt4AaABAg\n",
    "get_comment_data(os.path.join(\"data\", \"comment_data1.csv\"))['UgygOezB4Mvd5o6FgAt4AaABAg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = {}\n",
    "for file in comment_paths:\n",
    "    comments.update(get_comment_data(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q8\n",
    "#What is the length of the comment with ID UgztIaGfqFoiGvbOdfp4AaABAg\n",
    "comments['UgztIaGfqFoiGvbOdfp4AaABAg'].comment_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.86953042956443"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q9\n",
    "#What percentage of comments are at most 140 characters long?\n",
    "len([i for i in comments.values() if i.comment_length<=140])/len(comments) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UCIPPMRA040LQr5QPyJEbmXA'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q10\n",
    "#What is the author ID of the comment that has the highest number of likes?\n",
    "max_val = -1\n",
    "for i in comments.values():\n",
    "    if i.likes>max_val:\n",
    "        max_val = i.likes\n",
    "        max_id = i.author_id\n",
    "max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q11\n",
    "#calculate the most active hour for posting comment\n",
    "# dict of 24 hours\n",
    "hour_dict = {i:0 for i in range(24)}\n",
    "for i in comments.values():\n",
    "    hour_dict[int(i.published_at[11:13])] += 1\n",
    "sorted(hour_dict.items(), key=lambda x: x[1], reverse=True)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucketize the comments data by creating a dict mapping video IDs to a list of comment IDs corresponding to that video ID.\n",
    "comment_buckets = {}\n",
    "for i in comments:\n",
    "    if comments[i].video_id not in comment_buckets:\n",
    "        comment_buckets[comments[i].video_id] = [i]\n",
    "    else:\n",
    "        comment_buckets[comments[i].video_id].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "606"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#q12\n",
    "# How many comments does the video with ID A8rrr_w8rfk have?\n",
    "len(comment_buckets['A8rrr_w8rfk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(data_file, video_mapping_file):\n",
    "    \"\"\"\n",
    "    Given data_file (csv file) and video_mapping_file (json) file, generates a video\n",
    "    dictionary, mapping video ID to a dictionary containing title, and other details of the video.\n",
    "    Handles missing entry in video_ids.json by using try / except blocks to handle KeyError.\n",
    "    \"\"\"\n",
    "    data = process_csv(data_file)\n",
    "    header = data[0]\n",
    "    all_videos = data[1:]\n",
    "    video_mapping = get_mapping(video_mapping_file)\n",
    "    videos_dict = dict()\n",
    "    for video in all_videos: # You may find it helpful to do all_videos[:5] to only look at the first 5 videos.\n",
    "        try:\n",
    "            videos_dict[video[header.index(\"video_id\")]] = {\n",
    "                \"title\": video_mapping[video[header.index(\"video_id\")]],\n",
    "                \"channel_id\": video[header.index(\"channel_id\")],\n",
    "                \"published_at\": video[header.index(\"published_at\")],\n",
    "                \"duration\": video[header.index(\"duration\")],\n",
    "                \"category\": video[header.index(\"category\")],\n",
    "                \"tags\": video[header.index(\"tags\")],\n",
    "                \"views\": int(video[header.index(\"views\")]),\n",
    "                \"likes\": int(video[header.index(\"likes\")]),\n",
    "                \"dislikes\": int(video[header.index(\"dislikes\")]),\n",
    "            }\n",
    "        except KeyError:\n",
    "            continue\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return videos_dict\n",
    "videos = get_videos(os.path.join('data','video_data.csv'), os.path.join('data','video_ids.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf3a1eecdde00f0f7f98d2f5a25edfc92a721e7fdf8a41e706a436beaf8884df"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
