{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b59ab8a0",
   "metadata": {},
   "source": [
    "# Lab-P10: Files and Formats for Youtube Data\n",
    "\n",
    "In this lab, you'll get practice with files and formats, in preparation for p10. If you haven't already done so, make sure to download data.zip from Github and extract it to your lab10 folder. Your lab10 folder should contain the following:\n",
    "\n",
    "![Image showing lab10 folder contents](https://github.com/msyamkumar/cs220-s22-projects/blob/main/lab-p10/images/files.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbfb7d",
   "metadata": {},
   "source": [
    "## File Vocabulary\n",
    "\n",
    "For p10, you'll need to be familiar with the following file-related terms to know what we're asking you to do.\n",
    "\n",
    "Before we get started with the assignment, let's talk about the distinction between these terms, which will become important as we go along.\n",
    "\n",
    "* **Directory:** a collection of files and directories.  \"Folder\" is a less-technical synonym you've doubtless heard frequently.\n",
    "\n",
    "* **File Name:** a name you can use for a file if you know what directory you're in.  For example, `movies.csv`, `test.py`, and `main.ipynb` are examples of file names.  Note that different files can have the same name, as long as those files are in different directories.\n",
    "\n",
    "* **Path:** a more-complete name that tells you the file name AND what directory it is in. For example, `p8/main.ipynb` and `p9/main.ipynb` are examples of path names on a Mac, referring to a file named `main.ipynb` in the p8 directory and a second file with the same name in the p9 directory, respectively. Windows uses back-slashes instead of forward slashes, so on a Windows laptop the paths would be `p8\\main.ipynb` and `p9\\main.ipynb`. There may be more levels in a path to represent more levels of directories. For example, `courses\\cs220\\p8\\test.py` refers to the test.py file in the p8 directory, which is in the cs220 directory, which is in the courses directory.\n",
    "\n",
    "* **Absolute vs Relative Path:** A relative path specifies a location on your computer based on the current working directory (in this case, the folder you ran the jupyter notebook in). On the other hand, an absolute path specifies the location based on the root folder on your computer. As an example of both, the relative path to the `channel_ids1.json` file in the `data` folder would be `data/channel_ids1.json`, but the absolute path would look something like `C:/Users/Tim/Documents/Lab10/data/channel_ids1.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f2d308",
   "metadata": {},
   "source": [
    "You will also need to import the following libraries to complete the lab and project. We've gone ahead and filled them out for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ed3f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "\n",
    "# add code to import the os module\n",
    "import os\n",
    "# add code to import the csv module\n",
    "import csv\n",
    "# add code to import the json module\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb176425",
   "metadata": {},
   "source": [
    "## Segment 1: File and Directories\n",
    "\n",
    "### Task 1.1 Sort the output of os.listdir()\n",
    "`os.listdir` can be used to list the files of a directory. For example, `os.listdir(\".\")` would list the files in the current directory.\n",
    "\n",
    "Create a variable named `data_files` and save the names of the files in the \"data\" directory to it. Then, **sort** `data_files` based on the file's name.\n",
    "\n",
    "**Note:** You should *always* sort the output of `os.listdir()` because the output of `os.listdir()` is **OS dependent**. This means that if you run this code on a different OS, the paths might be sorted in a different order, which could lead to different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a5bd24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.channel_ids0.json',\n",
       " '.hidden.txt',\n",
       " 'channel_ids1.json',\n",
       " 'channel_ids2.json',\n",
       " 'channel_ids3.json',\n",
       " 'channel_ids4.json',\n",
       " 'channel_ids5.json',\n",
       " 'comment_data1.csv',\n",
       " 'comment_data2.csv',\n",
       " 'comment_data3.csv',\n",
       " 'comment_data4.csv',\n",
       " 'comment_data5.csv',\n",
       " 'video_data.csv',\n",
       " 'video_ids.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: read the names of the files in the \"data\" directory\n",
    "# TODO: sort the files by name\n",
    "# TODO: display data_files.\n",
    "data_files = os.listdir(\"data\")\n",
    "data_files.sort()\n",
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa71ea11",
   "metadata": {},
   "source": [
    "Your output should look like this...\n",
    "\n",
    "```python\n",
    "['.channel_ids0.json',\n",
    " '.hidden.txt',\n",
    " 'channel_ids1.json',\n",
    " 'channel_ids2.json',\n",
    " 'channel_ids3.json',\n",
    " 'channel_ids4.json',\n",
    " 'channel_ids5.json',\n",
    " 'comment_data1.csv',\n",
    " 'comment_data2.csv',\n",
    " 'comment_data3.csv',\n",
    " 'comment_data4.csv',\n",
    " 'comment_data5.csv',\n",
    " 'video_data.csv',\n",
    " 'video_data_shuffled.csv',\n",
    " 'video_ids.json']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446ee36d",
   "metadata": {},
   "source": [
    "### Task 1.2 Filter out `data_files` that start with \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75b3875",
   "metadata": {},
   "source": [
    "Now, create a new list using `data_files` that does not contain files that start with a \".\". Assign this new list to `data_files`. List comprehension may be helpful.\n",
    "\n",
    "Your output should be the same as Task 1.1, but without `.hidden.txt` and `.channel_ids0.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc05089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['channel_ids1.json',\n",
       " 'channel_ids2.json',\n",
       " 'channel_ids3.json',\n",
       " 'channel_ids4.json',\n",
       " 'channel_ids5.json',\n",
       " 'comment_data1.csv',\n",
       " 'comment_data2.csv',\n",
       " 'comment_data3.csv',\n",
       " 'comment_data4.csv',\n",
       " 'comment_data5.csv',\n",
       " 'video_data.csv',\n",
       " 'video_ids.json']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Filter out file names that begin with a \".\"\n",
    "res = []\n",
    "for i in os.listdir(\"data\"):\n",
    "    if i[0]!='.':\n",
    "        res.append(i)\n",
    "data_files = res\n",
    "data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74fc0a5",
   "metadata": {},
   "source": [
    "### Task 1.3 Use os.path.join() to create a path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db7d7bc",
   "metadata": {},
   "source": [
    "Tasks 1.1 and 1.2 asked you to list files in the current directory, but sometimes we may be interested in files in other locations. In this assignment, whenever we say \"path\", we are implying \"relative path\". Also, \"path\" and \"pathname\" are used interchangeablely. We will not be the using absolute path.\n",
    "\n",
    "For this Task, create a variable named `specific_file_path` for the file `channel_ids1.json` located in the `data` folder. Use `os.path.join` to join the directory name with the file name.\n",
    "\n",
    "**Note:** Always join paths using `os.path.join`. Never use the regular string `join` method, because the paths\n",
    "are **OS dependent**. If you hardcode `/` or `\\` in your paths, your code will not work on other computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c60235b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\channel_ids1.json'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_file_path = os.path.join(\"data\",\"channel_ids1.json\")\n",
    "specific_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b4aaa",
   "metadata": {},
   "source": [
    "Expected output for Windows users: `data\\channel_ids1.json` or `data\\\\channel_ids1.json`\n",
    "\n",
    "Expected output for Linux/Mac users: `data/channel_ids1.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b564f6c",
   "metadata": {},
   "source": [
    "### Task 1.4 Create a function that list files at a path location\n",
    "\n",
    "Using Tasks 1.1 and 1.2, write a function that returns a list of the files at a path location, ignoring files that start with a \".\". Files should be sorted alphabetically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a507f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in(pathname):\n",
    "    res = []\n",
    "    for i in os.listdir(pathname):\n",
    "        if(i[0]!='.'):\n",
    "            res.append(i)\n",
    "    sorted(res)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cd56a9",
   "metadata": {},
   "source": [
    "Your output should be the following...\n",
    "\n",
    "```python\n",
    "['channel_ids1.json',\n",
    " 'channel_ids2.json',\n",
    " 'channel_ids3.json',\n",
    " 'channel_ids4.json',\n",
    " 'channel_ids5.json',\n",
    " 'comment_data1.csv',\n",
    " 'comment_data2.csv',\n",
    " 'comment_data3.csv',\n",
    " 'comment_data4.csv',\n",
    " 'comment_data5.csv',\n",
    " 'video_data.csv',\n",
    " 'video_data_shuffled.csv',\n",
    " 'video_ids.json']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e809bd",
   "metadata": {},
   "source": [
    "Furthermore, if any of the following assertions fail, check your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "872f7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert '.hidden.txt' not in list_files_in('data')\n",
    "assert list_files_in(\"data\")[0] == 'channel_ids1.json'\n",
    "assert list_files_in(\"data\")[1] == 'channel_ids2.json'\n",
    "assert list_files_in(\"data\")[-1] == 'video_ids.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8758132",
   "metadata": {},
   "source": [
    "### Task 1.5 Create a function that outputs relative paths to files\n",
    "\n",
    "`list_files_in` takes in a path and returns a *list of file names*, but you can't open those files unless you join them with their relative path. Create a function called `list_paths_in` that creates a *list of pathnames* to those files.\n",
    "\n",
    "Be sure to use `os.path.join` like in Task 1.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7ed43ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_paths_in(pathname):\n",
    "    return [os.path.join(pathname,i) for i in list_files_in(pathname)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d769d9e",
   "metadata": {},
   "source": [
    "Your output should be the following (with `\\\\` being whatever file seperator your OS uses)...\n",
    "\n",
    "```python\n",
    "['data\\\\channel_ids1.json',\n",
    " 'data\\\\channel_ids2.json',\n",
    " 'data\\\\channel_ids3.json',\n",
    " 'data\\\\channel_ids4.json',\n",
    " 'data\\\\channel_ids5.json',\n",
    " 'data\\\\comment_data1.csv',\n",
    " 'data\\\\comment_data2.csv',\n",
    " 'data\\\\comment_data3.csv',\n",
    " 'data\\\\comment_data4.csv',\n",
    " 'data\\\\comment_data5.csv',\n",
    " 'data\\\\video_data.csv',\n",
    " 'data\\\\video_data_shuffled.csv',\n",
    " 'data\\\\video_ids.json']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0c0af",
   "metadata": {},
   "source": [
    "## Segment 2: JSON file format\n",
    "\n",
    "### Task 2.1 Load JSON Data\n",
    "Given the function `read_json` from lecture, load the data in `channel_ids1.json` into a variable called `json_data`. Remember, `channel_ids1.json` is located in the `data` directory.\n",
    "\n",
    "Use [Lecture 19 (JSON)](https://www.msyamkumar.com/cs220/s22/materials/lecture_ppts/lec_19_S22.pdf) as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7f618d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UCpi8TJfiA4lKGkaXs__YdBA': 'The Try Guys',\n",
       " 'UCERUmrDh9hmqEXBsnYFNTIA': 'DashieGames',\n",
       " 'UCIOrUVVyfoWnmcwG6IwCULQ': 'Loserfruit',\n",
       " 'UCR_J_SntqJh5eXw66d5hJxA': 'Matthew Beem',\n",
       " 'UCNye-wNBqNL5ZzHSJj3l8Bg': 'Al Jazeera English',\n",
       " 'UCHRTfR2r0Ss3UjFyw7gSA-A': 'Ryguyrocky',\n",
       " 'UCCbDhjYocBWYPTqoUONCPRA': 'Allie Schnacky',\n",
       " 'UCuN9hYw2RpoAW8rZ3VK3isA': 'NASCAR',\n",
       " 'UCugJq15BiB-c1NDYPHiznWQ': 'Total War',\n",
       " 'UCXVxMuWK6l_pCyxEk07EIRw': 'STARZ',\n",
       " 'UCRijo3ddMTht_IHyNSNXpNQ': 'Dude Perfect',\n",
       " 'UCEdTLCzuunuFLbAVfD1-Jpw': 'The Blondie Boys Shorts',\n",
       " 'UCq3QBWXCKvMnltjwqWuB5bQ': 'Cam&Fam',\n",
       " 'UCjbhchq-wEJBNJ-_faXsOmA': 'INTHESOOP_TV',\n",
       " 'UCjmJDM5pRKbUlVIzDYYWb6g': 'Warner Bros. Pictures',\n",
       " 'UC1T0JN1hhHfNsiKtqKn_dEQ': 'Sarah Schauer',\n",
       " 'UCA19mAJURyYHbJzhfpqhpCA': 'Action Lab Shorts',\n",
       " 'UCja8sZ2T4ylIqjggA1Zuukg': 'CBS Sports HQ',\n",
       " 'UC9PIn6-XuRKZ5HmYeu46AIw': 'Barely Sociable',\n",
       " 'UCXOE3YlluOUu_-5DdUUbAtw': 'WSOCTV9',\n",
       " 'UCUKi4zY5ETSqrKAjTBgjM-g': 'sWooZie',\n",
       " 'UCqZQlzSHbVJrwrn5XvzrzcA': 'NBC Sports',\n",
       " 'UCXcMEuLWTxA2D8IZcfouBiA': 'Davidjustinn',\n",
       " 'UCwx2yZG4irNLMDBuB-JGxMw': 'TapWater',\n",
       " 'UClOf1XXinvZsy4wKPAkro2A': 'PlayOverwatch',\n",
       " 'UCeBnbqt4VRhotq2TQjkIi2A': 'LaurenzSide',\n",
       " 'UCSo19KhHogXxu3sFsOpqrcQ': 'TUDN USA',\n",
       " 'UCkDtCKtPKlsg-gJO_m5D0mQ': 'Telepurte',\n",
       " 'UC-SV8-bUJfXjrRMnp7F8Wzw': 'Roman Atwood Vlogs',\n",
       " 'UCJcQeT8LADOXRROXCGM4dRg': 'TheCrazyGorilla',\n",
       " 'UCKaCalz5N5ienIbfPzEbYuA': 'Jordan Matter',\n",
       " 'UCF9imwPMSGz4Vq1NiTWCC7g': 'Paramount Pictures',\n",
       " 'UCY30JRSgfhYXA6i6xX1erWg': 'Smosh',\n",
       " 'UCE86oyLVAcsSkRAEWVtDUlA': '4 Shooters Only',\n",
       " 'UCe7cIhm4_RWsThRzBCXtmOQ': 'ABC11',\n",
       " 'UCOxoGn23BBHWghJelrqGkhg': 'Braydon Price',\n",
       " 'UCzMjRlKVO9XIqH_crIFpi6w': 'Skeppy',\n",
       " 'UCqseWqrl7r-hNoWme7hIfTw': 'Rebecca Rogers (Mrs. Rogers)',\n",
       " 'UCYCOimM5ykUJO4WrZD7kDeQ': 'Jaycoset',\n",
       " 'UCxl79GCsb6-xhrdQuPgnuJA': 'Acura',\n",
       " 'UCq0OueAsdxH6b8nyAspwViw': 'Universal Pictures',\n",
       " 'UCY8SLLJjWpS4sx1dEqECaIw': 'Tyler Oliveira',\n",
       " 'UC4ijq8Cg-8zQKx8OH12dUSw': 'Kara and Nate',\n",
       " 'UCnmGIkw-KdI0W5siakKPKog': 'Ryan Trahan',\n",
       " 'UCHxSZ6vUjipY6rf4bWnIJ1A': 'watchyourhaircut',\n",
       " 'UCE_--R1P5-kfBzHTca0dsnw': 'Complex',\n",
       " 'UCTz8K5TMmkQkRArybXfoVDg': 'Investment Joy',\n",
       " 'UCjpPTefVqOp_sPToSyUaEMg': 'Mr.Askick',\n",
       " 'UC1KsxDW7hhfeq5QQmFtInIw': 'julien solomita',\n",
       " 'UC0h07r_UgTD0Tc-Dn5XLX3g': 'Wisp',\n",
       " 'UC6QWhGQqf0YDYdRb0n6ojWw': 'Brooklyn and Bailey',\n",
       " 'UCDZH6sjXpWd1k9kJyXJZn9g': 'Cj Dachamp',\n",
       " 'UCPgMAS8woHJ_o_OZdTR7kcQ': 'Peacock',\n",
       " 'UCcW055_DGSkCEGWoKsW7gFQ': 'scribblejuice',\n",
       " 'UC-8zLYB2DB1fFCP3KJxe0Sg': 'MiniBloxia',\n",
       " 'UC2D-GCxeE69hCUmRwISXABw': 'Logdotzip',\n",
       " 'UChKqgm5CfsjC_bXiZlVnACA': 'Bigwunna',\n",
       " 'UCRw5sR-ZubiAr3Dxh_sJ64w': 'THE WADS',\n",
       " 'UCVJgocEWT3u49_4GtulGHnQ': 'Off Grid w/ Jake & Nicolle',\n",
       " 'UChFDOD4WPd2FgTCkSA4qzXg': \"Vader's Fortress\",\n",
       " 'UC7FldPQ7aT7Slikg7tZc30g': 'Mitten Squad',\n",
       " 'UCY4AlDv6wL2qhrX29iwdqAg': '2HYPE',\n",
       " 'UCUaT_39o1x6qWjz7K2pWcgw': 'Beast Reacts',\n",
       " 'UC3L9XPe0_FGfRG-CMGtBvFg': 'JxmyHighroller',\n",
       " 'UCSUf5_EPEfl4zlBKZHkZdmw': 'Danny Gonzalez',\n",
       " 'UC9tXyGZiEft9J4ZiI8dHb3Q': 'TapL',\n",
       " 'UCxDZs_ltFFvn0FDHT6kmoXA': 'bald and bankrupt',\n",
       " 'UCQ7Lqg5Czh5djGK6iOG53KQ': 'Wolves',\n",
       " 'UC6nSFpj9HTCZ5t-N3Rm3-HA': 'Vsauce',\n",
       " 'UCKQECjul8nw1KW_JzfBTP1A': 'KPRC 2 Click2Houston',\n",
       " 'UCLaduTRRWdzU8kq9AoqTRlw': 'RellGames',\n",
       " 'UCXMwCQVey4PhdWFJ6WhAVhA': 'SockStudios',\n",
       " 'UCtWIUAvZuWaNorJImG2Riqg': 'Damn Seconds',\n",
       " 'UCo00rI10S3Wpk4hVkL5IDTg': 'Alex Choi',\n",
       " 'UCJbYdyufHR-cxOuY96KIoqA': 'AMP',\n",
       " 'UC-O9o5coq8iFSVthivq__tw': 'Lexi Hensler',\n",
       " 'UCFKDEp9si4RmHFWJW1vYsMA': 'EthosLab',\n",
       " 'UCvNBXWGykQrWb7kPAn5eLUQ': 'Battlefield',\n",
       " 'UCEvC-HQ7ST5h8iC1IDgVtgw': 'Telanthric',\n",
       " 'UCBVEb6W9dMpIConICMS0B5Q': 'ImNotaCasualty',\n",
       " 'UChnGFN2LRHBq-0PM6dOaq5A': 'Bachelor Nation',\n",
       " 'UCIPPMRA040LQr5QPyJEbmXA': 'MrBeast Gaming',\n",
       " 'UCpIafFPGutTAKOBHMtGen7g': 'Gus Johnson',\n",
       " 'UCiS882YPwZt1NfaM0gR0D9Q': 'Genshin Impact',\n",
       " 'UCsEgeyBfOnGGBpjIvkDJbWg': 'Socksfor1',\n",
       " 'UCh8gHdtzO2tXd593_bjErWg': 'Doobydobap',\n",
       " 'UC_ovJB6xS99RQGIq7ik5T_A': 'Benny Soliven',\n",
       " 'UC35TiyFAjzQCyOrFt5ccbhw': 'JGGLS',\n",
       " 'UCpOXWy4Erc4UNoxI9xW-CXw': 'Steel Wool Studios',\n",
       " 'UCSJWlswfVUgyVliZaEFoaBw': 'TheSorryGirls',\n",
       " 'UCfPUcG3oCmXEYgdFuwlFh8w': 'Dingo Doodles',\n",
       " 'UCBgcPSn61UQ4l_-FvcEgLQA': 'NBC 6 South Florida',\n",
       " 'UC0Eqb484X8EiNrFLSUQVsaA': 'SoundSmith'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_json(path):\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return json.load(f) # dict, list, etc\n",
    "\n",
    "# TODO: invoke read_json - make sure to use os.path.join to generate the releative path to \"channel_ids1.json\"\n",
    "json_data = read_json(list_paths_in(\"data\")[0])\n",
    "json_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1409ca",
   "metadata": {},
   "source": [
    "If any of the following assertions fail, check your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f36295",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert json_data['UCqZQlzSHbVJrwrn5XvzrzcA'] == 'NBC Sports'\n",
    "assert json_data['UCh8gHdtzO2tXd593_bjErWg'] == 'Doobydobap'\n",
    "assert json_data['UCRijo3ddMTht_IHyNSNXpNQ'] == 'Dude Perfect'\n",
    "assert json_data['UC6nSFpj9HTCZ5t-N3Rm3-HA'] == 'Vsauce'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0526a1",
   "metadata": {},
   "source": [
    "### Task 2.2 Handle JSONDecodeError\n",
    "\n",
    "Define the function `get_mapping` that uses the `read_json` function above.\n",
    "\n",
    "The `read_json` function can throw an error! If the JSON file is formatted incorrectly (missing a closing brace, missing a value for a key, or some other syntax error), a JSONDecodeError will occur. If you encounter a malformed JSON file like this, you should return an empty dictionary.\n",
    "\n",
    "Use a try/except to catch *only* a `json.JSONDecodeError`. See [Lecture 25 (Error Handling)](https://www.msyamkumar.com/cs220/s22/materials/lecture_ppts/lec_25_S22.pdf) for reference.\n",
    "\n",
    "*Note:* If you used `import json` and try to catch a `JSONDecodeError`, you will get the following error:\n",
    "```\n",
    "NameError: name 'JSONDecodeError' is not defined\n",
    "```\n",
    "You can either catch a `json.JSONDecodeError` instead, or add `from json import JSONDecodeError` to your import statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52bbc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define this function; make sure it handles malformed JSON files! \n",
    "def get_mapping(pathname):\n",
    "    \"\"\"\n",
    "    Given a path called pathname, load the json data at the path and return the loaded json data.\n",
    "    If a json.JSONDecodeError is thrown, an empty dictionary is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pass\n",
    "    except json.JSONDecodeError as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c90ae240",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\24506\\Documents\\cs220\\p10\\practice.ipynb Cell 29'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/24506/Documents/cs220/p10/practice.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39m# Make sure your code passes the assertions below.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/24506/Documents/cs220/p10/practice.ipynb#ch0000028?line=1'>2</a>\u001b[0m mapping \u001b[39m=\u001b[39m get_mapping(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mchannel_ids2.json\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/24506/Documents/cs220/p10/practice.ipynb#ch0000028?line=2'>3</a>\u001b[0m \u001b[39massert\u001b[39;00m mapping[\u001b[39m'\u001b[39;49m\u001b[39mUCRlEFn0L2G_DktbyvN0AZ5A\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mWadZee\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/24506/Documents/cs220/p10/practice.ipynb#ch0000028?line=3'>4</a>\u001b[0m \u001b[39massert\u001b[39;00m mapping[\u001b[39m'\u001b[39m\u001b[39mUCDVYQ4Zhbm3S2dlz7P1GBDg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNFL\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/24506/Documents/cs220/p10/practice.ipynb#ch0000028?line=4'>5</a>\u001b[0m \u001b[39massert\u001b[39;00m mapping[\u001b[39m'\u001b[39m\u001b[39mUC06E4Y_-ybJgBUMtXx8uNNw\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTheBackyardScientist\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Make sure your code passes the assertions below.\n",
    "mapping = get_mapping(os.path.join(\"data\", \"channel_ids2.json\"))\n",
    "assert mapping['UCRlEFn0L2G_DktbyvN0AZ5A'] == 'WadZee'\n",
    "assert mapping['UCDVYQ4Zhbm3S2dlz7P1GBDg'] == 'NFL'\n",
    "assert mapping['UC06E4Y_-ybJgBUMtXx8uNNw'] == 'TheBackyardScientist'\n",
    "assert get_mapping(os.path.join(\"data\", \"channel_ids5.json\")) == {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cecb8",
   "metadata": {},
   "source": [
    "This test ensures that you do not catch anything besides a `JSONDecodeError`. It's a bit fishy, so if you get `TypeError: 'NoneType' object is not callable`, try Restart and Run all. If that doesn't work, ask a TA to help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d723fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't have to understand this code. \n",
    "# Just know that, if your get_mapping is correct, this code does nothing.\n",
    "\n",
    "old_load = json.load\n",
    "try:\n",
    "    json.load = None\n",
    "    get_mapping(os.path.join(\"data\", \"channel_ids1.json\"))\n",
    "    assert False   \n",
    "except AssertionError:\n",
    "    print(\"Failed: You caught an exception besides JSONDecodeError\")\n",
    "except:\n",
    "    pass\n",
    "json.load = old_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c1708",
   "metadata": {},
   "source": [
    "## Segment 3: Video Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468f934",
   "metadata": {},
   "source": [
    "### Task 3.1: Familiarize yourself with the video data files files\n",
    "\n",
    "Examine the contents of `video_data.csv`. For example, the first two rows look like this:\n",
    "\n",
    "```python\n",
    "[['video_id',\n",
    "  'channel_id',\n",
    "  'published_at',\n",
    "  'duration',\n",
    "  'category',\n",
    "  'tags',\n",
    "  'views',\n",
    "  'likes',\n",
    "  'dislikes'],\n",
    " ['ex98DxvUiAc',\n",
    "  'UC94lW_-Hr_uA7RcJ3D-WPOg',\n",
    "  '2021-10-01 01:54:20',\n",
    "  '00:15:12',\n",
    "  'Comedy',\n",
    "  'danny duncan|danny duncan 69|danny duncan vlog|danny duncan pranks|danny duncan vlogs|vlogs|pranks|danny duncan tour|danny duncan florida|danny duncan merch',\n",
    "  '3250076',\n",
    "  '146039',\n",
    "  '1800']]\n",
    "```   \n",
    "\n",
    "Also examine `video_ids.json`, which contains a mapping of the video IDs to the title of the video. It looks like this:  \n",
    "\n",
    "```python\n",
    "{'ex98DxvUiAc': 'Guess Who’s Back!',\n",
    " '8y9QnS_tMkY': 'The Ultimate \"Kung Fu Panda\" Recap Cartoon',\n",
    " 'IwTkLFYYBKc': 'Old Master, New Tricks! (Clash of Clans Season Challenges)',\n",
    " ...}\n",
    "```\n",
    "\n",
    "Our goal is to combine the data from these two files.\n",
    "\n",
    "In order to do this, we must be able to load data from CSV and JSON files.\n",
    "\n",
    "**Note:** When reading in a CSV, do not use `csv.DictReader` to read the csv files; use `process_csv`. Run the cell below, it will be used in the following tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# source:  Automate the Boring Stuff with Python Ch 12\n",
    "def process_csv(filename):\n",
    "    exampleFile = open(filename, encoding=\"utf-8\")  \n",
    "    exampleReader = csv.reader(exampleFile) \n",
    "    exampleData = list(exampleReader)        \n",
    "    exampleFile.close()  \n",
    "    return exampleData\n",
    "\n",
    "\n",
    "# TODO: invoke process_csv - make sure to use os.path.join \n",
    "#       to generate the relative path to \"video_data.csv\"\n",
    "# TODO: split the header and the data into the those variables\n",
    "# TODO: Use print function calls to display header and data's first list entry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2042206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: invoke read_json - make sure to use os.path.join \n",
    "#       to generate the releative path to \"video_ids.json\"\n",
    "# TODO: display the dictionary returned by read_json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc9cc56",
   "metadata": {},
   "source": [
    "### Task 3.2: Lookups using videos dictionary\n",
    "\n",
    "Recall that each video has a `video_id` that can be combined with the mapping from `video_ids.json` to obtain the `title` of each video. For example the video with ID `ex98DxvUiAc` has the title `'Guess Who’s Back!'`.\n",
    "\n",
    "Below, given the following `sample_video_id`, store its corresponding title to `sample_video_title`, by using dict lookup operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d1132",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_video_id = \"4P8fKd0IVOs\"\n",
    "???\n",
    "\n",
    "assert sample_video_title == 'How Does The James Webb Space Telescope Work? - Smarter Every Day 262'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638960fe",
   "metadata": {},
   "source": [
    "Now, we want to generalize this to all videos. You will be writing a function called `get_videos`, which will be very similar to the `get_movies` function from P8 and P9. Each video will be represented as a dictionary of its title and all its attributes in the columns above. To keep things simple, let's start by assuming each video only has a `title` like this:\n",
    "\n",
    "```python\n",
    "{'title': 'The Ultimate \"Kung Fu Panda\" Recap Cartoon'}\n",
    "```\n",
    "\n",
    "We want to do this for each video, mapping their `video_id` to a dictionary of the video, so our end goal is something like this...\n",
    "\n",
    "```python\n",
    "{\n",
    " 'ex98DxvUiAc': {'title': 'Guess Who’s Back!'},\n",
    " '8y9QnS_tMkY': {'title': 'The Ultimate \"Kung Fu Panda\" Recap Cartoon'},\n",
    " 'IwTkLFYYBKc': {'title': 'Old Master, New Tricks! (Clash of Clans Season Challenges)'},\n",
    " '2_9LOiY9Lpc': {'title': 'Making Spiral Light'},\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "Complete the function `get_videos` below.\n",
    "\n",
    "**Note:** There exists some videos in `video_data.csv` that don't exist in `video_ids.json`. If you get a KeyError, skip that video. A try/except will be useful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c2d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_videos(data_file, video_mapping_file):\n",
    "    \"\"\"\n",
    "    Given data_file (csv file) and video_mapping_file (json) file, generates a video\n",
    "    dictionary, mapping video ID to a dictionary containing title, and other details of the video.\n",
    "    Handles missing entry in video_ids.json by using try / except blocks to handle KeyError.\n",
    "    \"\"\"\n",
    "    data = process_csv(data_file)\n",
    "    header = data[0]\n",
    "    all_videos = data[1:]\n",
    "    video_mapping = get_mapping(video_mapping_file)\n",
    "    videos_dict = dict()\n",
    "    for video in all_videos: # You may find it helpful to do all_videos[:5] to only look at the first 5 videos.\n",
    "        pass \n",
    "        # TODO: for start, use print function call to display each video row\n",
    "        # TODO: Construct the dictionary.\n",
    "    return videos_dict\n",
    "\n",
    "videos = get_videos(os.path.join('data','video_data.csv'), os.path.join('data','video_ids.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953aeac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you pass the following tests:\n",
    "assert videos['fkMW60W180E']['title'] == 'SWAWS | Totally Accurate Battlegrounds'\n",
    "\n",
    "# This is how we test whether you hardcoded the column indices\n",
    "shuffled_videos = get_videos(os.path.join(\"data\", 'video_data_shuffled.csv'), \\\n",
    "                             os.path.join(\"data\", 'video_ids.json'))\n",
    "assert videos['fkMW60W180E']['title'] == shuffled_videos['fkMW60W180E']['title'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca901a0",
   "metadata": {},
   "source": [
    "**Warning:** `video_data_shuffled.csv` is *not* part of the dataset for the project. When you start on p10, either download the data.zip for p10 from the github repo, or delete `video_data_shuffled.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c8a3ba",
   "metadata": {},
   "source": [
    "### Task 3.3: More basic data\n",
    "\n",
    "Great. We now have the structure of videos ready. Go back and modify `get_videos` to add the following data to each video:\n",
    "- published_at\n",
    "- duration\n",
    "- category\n",
    "- views (should be an int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44924e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert videos['fkMW60W180E']['published_at'] == \"2021-10-12 19:01:41\"\n",
    "assert videos['fkMW60W180E']['duration'] == \"00:18:46\"\n",
    "assert videos['fkMW60W180E']['category'] == \"Gaming\"\n",
    "assert videos['fkMW60W180E']['views'] == 3172185\n",
    "\n",
    "# this is how we test whether you hardcoded the column indices\n",
    "shuffled_videos = get_videos(os.path.join(\"data\", 'video_data_shuffled.csv'), \\\n",
    "                             os.path.join(\"data\", 'video_ids.json'))\n",
    "assert shuffled_videos['fkMW60W180E']['published_at'] == \"2021-10-12 19:01:41\"\n",
    "assert shuffled_videos['fkMW60W180E']['category'] == \"Gaming\"\n",
    "assert shuffled_videos['fkMW60W180E']['views'] == 3172185\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed7a37",
   "metadata": {},
   "source": [
    "### Task 3.4: Add tags to your video dictionaries\n",
    "\n",
    "Now, add the `tags` key to each video dictionary.\n",
    "\n",
    "*Note:* The tags are stored as a string of the form\n",
    "\n",
    "```python\n",
    "'Science|quantum physics|the action lab'\n",
    "```\n",
    "\n",
    "and you need store them as a list that looks like:\n",
    "\n",
    "```python\n",
    "['Science', 'quantum physics', 'the action lab']\n",
    "```\n",
    "\n",
    "What method might be useful for processing these tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e490295b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: modify your get_videos function so that each video dictionary also has a tags key\n",
    "# Make sure it passes the following test:\n",
    "\n",
    "assert videos['fkMW60W180E']['tags'] == ['tot',\n",
    "  'totally accurate battlegrounds',\n",
    "  'tabg',\n",
    "  'totally accurate battle simulator',\n",
    "  'totally accurate battlegrounds gameplay',\n",
    "  'totally accurate battle grounds',\n",
    "  'tabg gameplay',\n",
    "  'tabg game',\n",
    "  'tabs',\n",
    "  'totally accurate',\n",
    "  'totally accurate battle royale',\n",
    "  'battle royale',\n",
    "  'tabg funny',\n",
    "  'fortnite',\n",
    "  'battlegrounds',\n",
    "  'tabs battle royale',\n",
    "  'new battle royale',\n",
    "  'pubg',\n",
    "  'totally accurate battlegrounds funny',\n",
    "  'swaws',\n",
    "  'swaws meme',\n",
    "  'swaws russian badger',\n",
    "  'tabg update',\n",
    "  'tabg win',\n",
    "  'tabg br',\n",
    "  'free to play pc games',\n",
    "  'free to play']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771adc8d",
   "metadata": {},
   "source": [
    "### Task 3.5: Add likes, dislikes and ratings_enabled\n",
    "\n",
    "Some videos have their ratings disabled. We will assume that ratings have been disabled if `likes` or `dislikes` have a value of `''` (the empty string). Each video will have `likes`, `dislikes` and `ratings_enabled` as follows:\n",
    "\n",
    "- `ratings_enabled` is True if neither `likes` nor `dislikes` is `''`. Otherwise, it is False.\n",
    "- The value stored for `likes` and `dislikes` should be `None` if `ratings_enabled` is False.\n",
    "- If `ratings_enabled` is True, then `likes` and `dislikes` should just be stored as the ints we read from the csv.\n",
    "\n",
    "Go back and modify `get_videos` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f79d8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert videos['fkMW60W180E']['likes'] == 210951\n",
    "assert videos['fkMW60W180E']['dislikes'] == 1824\n",
    "assert videos['fkMW60W180E']['ratings_enabled'] == True\n",
    "\n",
    "assert videos['UeFnH1DKYIE']['likes'] == None\n",
    "assert videos['UeFnH1DKYIE']['dislikes'] == None\n",
    "assert videos['UeFnH1DKYIE']['ratings_enabled'] == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1784c03",
   "metadata": {},
   "source": [
    "There's a few more modifications we need to make to `get_videos`, such as reading in the channel name, but we'll do that in the project. That's it for the lab! Feel free to start working on p10. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
